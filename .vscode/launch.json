{
    // Use IntelliSense to learn about possible attributes.
    // Hover to view descriptions of existing attributes.
    // For more information, visit: https://go.microsoft.com/fwlink/?linkid=830387
    "version": "0.2.0",
    "configurations": [
        {
            "name": "prep_covost_data",
            "type": "python",
            "request": "launch",
            "program": "mST/prepare_data/prep_covost_data.py",
            "console": "integratedTerminal",
            "args": [
                "--data-root",
                "/mnt/raid0/siqi/datasets/covost2/",
                "--src-lang",
                "zh-CN",
                "--tgt-lang",
                "en"
            ]
        },
        {
            "name": "gen",
            "type": "python",
            "request": "launch",
            "program": "fairseq_cli/generate.py",
            "console": "integratedTerminal",
            "cwd": "/mnt/nvme/siqi/work/projects/Chimera-ST",
            "args": [
                "../../datasets/must-c/en-de",
                "--gen-subset",
                "debug",
                "--task",
                "speech_to_text",
                "--path",
                "/mnt/raid0/siqi/checkpoints/w2v_transformer/checkpoint_83_150002.pt",
                "--max-tokens",
                "1000000",
                "--max-source-positions",
                "1000000",
                "--beam",
                "4",
                "--scoring",
                "sacrebleu",
                "--config-yaml",
                "config_wave.yaml",
                "--lenpen",
                "1.0"
            ]
        },
        {
            "name": "st",
            "type": "python",
            "request": "launch",
            "program": "train.py",
            "console": "integratedTerminal",
            "cwd": "/home/siqiouyang/work/projects/mST",
            "env": {
                "CUDA_VISIBLE_DEVICES": "0"
            },
            "args": [
                "/mnt/data/siqiouyang/datasets/covost2",
                "--distributed-world-size",
                "1",
                "--task",
                "multilingual_triplet_align_cluster_task",
                "--train-subset",
                "de_en_train,pt_en_train",
                "--valid-subset",
                "de_en_dev,pt_en_dev",
                "--max-tokens",
                "500000",
                "--max-source-positions",
                "500000",
                "--save-dir",
                "/mnt/data/siqiouyang/runs/mST/debug_cluster",
                "--save-interval-updates",
                "5",
                "--save-interval",
                "1",
                "--keep-last-epochs",
                "1",
                "--keep-interval-updates",
                "20",
                "--tensorboard-logdir",
                "tensorboard_logs/debug",
                "--config-yaml",
                "config_mST.yaml",
                "--criterion",
                "multilingual_triplet_align_cluster_criterion",
                "--label-smoothing",
                "0.1",
                "--report-accuracy",
                "--loss-ratio",
                "1.0", "1.0", "1.0", "1.0", "0.0", "0.", "1.",
                "--use-emb",
                // "--gamma",
                // "0.1",
                // "--contrast-layer",
                // "13",
                // "--gamma",
                // "0.05",
                "--ignore-prefix-size",
                "1",
                "--arch",
                "xlsr_mbart50_base",
                "--w2v2-model-path",
                "/mnt/data/siqiouyang/runs/mST/pretrained/xlsr2_300m.pt",
                "--mbart50-dir",
                "/mnt/data/siqiouyang/runs/mST/pretrained/mbart50.ft.n1",
                "--cnn-subsampler",
                "--optimizer",
                "adam",
                "--clip-norm",
                "10.0",
                "--lr",
                "2e-4",
                "--lr-scheduler",
                "inverse_sqrt",
                "--weight-decay",
                "0.0",
                "--max-update",
                "150000",
                "--warmup-updates",
                "25000",
                "--update-freq",
                "8",
                "--num-workers",
                "1",
                "--ddp-backend",
                "no_c10d",
                // "--eval-bleu",
                // "--eval-bleu-detok",
                // "moses",
                // "--eval-bleu-remove-bpe",
                // "--eval-bleu-print-samples",
                // "--eval-bleu-bpe",
                // "sentencepiece",
                // "--eval-bleu-bpe-path",
                // "/mnt/data/siqiouyang/runs/mST/pretrained/mbart50.ft.n1/sentence.bpe.model",
                // "--best-checkpoint-metric",
                // "bleu",
                // "--maximize-best-checkpoint-metric",
                // "--fp16",
                "--seed",
                "1",
                "--reset-optimizer",
                "--reset-dataloader",
                // "--fp16",
                // "--disc-period", "3"
            ]
        },
        {
            "name": "mt",
            "type": "python",
            "request": "launch",
            "program": "train.py",
            "console": "integratedTerminal",
            "args": [
                "/home/ubuntu/work/datasets/wmt14/en-de/bin",
                "--task",
                "translation",
                "--train-subset",
                "train",
                "--valid-subset",
                "valid",
                "--save-dir",
                "/home/ubuntu/work/experiments/checkpoints/mt",
                "--max-tokens",
                "8192",
                "--criterion",
                "label_smoothed_cross_entropy",
                "--label-smoothing",
                "0.1",
                "--eval-bleu-args",
                "{\"beam\": 5, \"max_len_a\": 1.2, \"max_len_b\": 10}",
                "--eval-bleu",
                "--eval-bleu-detok",
                "moses",
                "--eval-bleu-remove-bpe",
                "--eval-bleu-bpe",
                "sentencepiece",
                "--eval-bleu-bpe-path",
                "/home/ubuntu/work/datasets/wmt14/en-de/wmt14_en_de/spm/spm_unigram10000_wave_joint.model",
                "--eval-bleu-print-samples",
                "--best-checkpoint-metric",
                "bleu",
                "--maximize-best-checkpoint-metric",
                "--arch",
                "cs291k_model_base",
                "--share-decoder-input-output-embed",
                "--w2v2-model-path",
                "/home/ubuntu/work/experiments/checkpoints/pretrained/wav2vec_small.pt",
                "--optimizer",
                "adam",
                "--adam-betas",
                "(0.9, 0.98)",
                "--clip-norm",
                "0.0",
                "--lr",
                "5e-4",
                "--lr-scheduler",
                "inverse_sqrt",
                "--weight-decay",
                "0.0001",
                "--max-update",
                "1000",
                "--warmup-updates",
                "4000",
                "--update-freq",
                "4",
                "--num-workers",
                "1",
                "--ddp-backend",
                "no_c10d",
                "--seed",
                "1"
            ]
        },
        {
            "name": "prep_mustc_data",
            "type": "python",
            "request": "launch",
            "program": "cs291k/prepare_data/prep_mustc_data.py",
            "console": "integratedTerminal",
            "args": [
                "--data-root",
                "/home/ubuntu/work/datasets/must-c/",
                "--task",
                "wave",
                "--ignore_fbank80",
                "--joint_spm",
                "wmt14-en-de-spm",
                "--languages",
                "de",
                "--vocab-type",
                "unigram",
                "--vocab-size",
                "10000"
            ]
        }
    ]
}