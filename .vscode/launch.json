{
    // Use IntelliSense to learn about possible attributes.
    // Hover to view descriptions of existing attributes.
    // For more information, visit: https://go.microsoft.com/fwlink/?linkid=830387
    "version": "0.2.0",
    "configurations": [
        {
            "name": "Python: Current File",
            "type": "python",
            "request": "launch",
            "program": "${file}",
            "console": "integratedTerminal"
        },
        {
            "name": "prep_covost_data",
            "type": "python",
            "request": "launch",
            "program": "mST/prepare_data/prep_covost_data.py",
            "console": "integratedTerminal",
            "args": [
                "--data-root",
                "/mnt/raid0/siqi/datasets/covost2/",
                "--src-lang",
                "zh-CN",
                "--tgt-lang",
                "en"
            ]
        },
        {
            "name": "gen",
            "type": "python",
            "request": "launch",
            "program": "fairseq_cli/generate.py",
            "console": "integratedTerminal",
            "cwd": "/mnt/nvme/siqi/work/projects/Chimera-ST",
            "args": [
                "../../datasets/must-c/en-de",
                "--gen-subset",
                "debug",
                "--task",
                "speech_to_text",
                "--path",
                "/mnt/raid0/siqi/checkpoints/w2v_transformer/checkpoint_83_150002.pt",
                "--max-tokens",
                "1000000",
                "--max-source-positions",
                "1000000",
                "--beam",
                "4",
                "--scoring",
                "sacrebleu",
                "--config-yaml",
                "config_wave.yaml",
                "--lenpen",
                "1.0"
            ]
        },
        {
            "name": "st",
            "type": "python",
            "request": "launch",
            "program": "train.py",
            "console": "integratedTerminal",
            "cwd": "/mnt/nvme/siqi/work/projects/Chimera-ST",
            "env": {
                "CUDA_VISIBLE_DEVICES": "0",
                "COVOST2_ROOT": "/mnt/raid0/siqi/datasets/covost2",
                "EXP_ID": "debug",
                "SAVE_DIR": "/mnt/raid0/siqi/checkpoints/debug",
                "TB_DIR": "tensorboard_logs",
                "W2V2_PATH": "/mnt/raid0/siqi/checkpoints/pretrained/xlsr2_300m.pt",
                "mBART50_DIR": "/mnt/raid0/siqi/checkpoints/pretrained/mbart50.ft.n1",
                "max_updates": "150000",
                "num_gpus": "1",
                "seed": "1"
            },
            "args": [
                "/mnt/raid0/siqi/datasets/covost2",
                "--task",
                "multilingual_triplet_task",
                "--train-subset",
                "zh-CN_en_train",
                "--valid-subset",
                "zh-CN_en_dev",
                "--max-tokens",
                "2000000",
                "--max-source-positions",
                "2000000",
                "--save-dir",
                "/mnt/raid0/siqi/checkpoints/debug",
                "--save-interval-updates",
                "5",
                "--save-interval",
                "1",
                "--keep-last-epochs",
                "1",
                "--keep-interval-updates",
                "20",
                "--tensorboard-logdir",
                "tensorboard_logs/debug",
                "--config-yaml",
                "config_mST.yaml",
                "--criterion",
                "multilingual_triplet_criterion",
                "--label-smoothing",
                "0.1",
                "--report-accuracy",
                "--loss-ratio",
                "1.0",
                "1.0",
                "1.0",
                "--ignore-prefix-size",
                "1",
                "--arch",
                "xlsr_mbart50_base",
                "--w2v2-model-path",
                "/mnt/raid0/siqi/checkpoints/pretrained/xlsr2_300m.pt",
                "--mbart50-dir",
                "/mnt/raid0/siqi/checkpoints/pretrained/mbart50.ft.n1",
                "--cnn-subsampler",
                "--optimizer",
                "adam",
                "--clip-norm",
                "10.0",
                "--lr",
                "2e-4",
                "--lr-scheduler",
                "inverse_sqrt",
                "--weight-decay",
                "0.0",
                "--max-update",
                "150000",
                "--warmup-updates",
                "25000",
                "--update-freq",
                "8",
                "--num-workers",
                "1",
                "--ddp-backend",
                "no_c10d",
                "--eval-bleu",
                "--eval-bleu-detok",
                "moses",
                "--eval-bleu-remove-bpe",
                "--eval-bleu-print-samples",
                "--eval-bleu-bpe",
                "sentencepiece",
                "--eval-bleu-bpe-path",
                "/mnt/raid0/siqi/checkpoints/pretrained/mbart50.ft.n1/sentence.bpe.model",
                "--best-checkpoint-metric",
                "bleu",
                "--maximize-best-checkpoint-metric",
                // "--fp16",
                "--seed",
                "1",
                "--reset-optimizer"
            ]
        },
        {
            "name": "mt",
            "type": "python",
            "request": "launch",
            "program": "train.py",
            "console": "integratedTerminal",
            "args": [
                "/home/ubuntu/work/datasets/wmt14/en-de/bin",
                "--task",
                "translation",
                "--train-subset",
                "train",
                "--valid-subset",
                "valid",
                "--save-dir",
                "/home/ubuntu/work/experiments/checkpoints/mt",
                "--max-tokens",
                "8192",
                "--criterion",
                "label_smoothed_cross_entropy",
                "--label-smoothing",
                "0.1",
                "--eval-bleu-args",
                "{\"beam\": 5, \"max_len_a\": 1.2, \"max_len_b\": 10}",
                "--eval-bleu",
                "--eval-bleu-detok",
                "moses",
                "--eval-bleu-remove-bpe",
                "--eval-bleu-bpe",
                "sentencepiece",
                "--eval-bleu-bpe-path",
                "/home/ubuntu/work/datasets/wmt14/en-de/wmt14_en_de/spm/spm_unigram10000_wave_joint.model",
                "--eval-bleu-print-samples",
                "--best-checkpoint-metric",
                "bleu",
                "--maximize-best-checkpoint-metric",
                "--arch",
                "cs291k_model_base",
                "--share-decoder-input-output-embed",
                "--w2v2-model-path",
                "/home/ubuntu/work/experiments/checkpoints/pretrained/wav2vec_small.pt",
                "--optimizer",
                "adam",
                "--adam-betas",
                "(0.9, 0.98)",
                "--clip-norm",
                "0.0",
                "--lr",
                "5e-4",
                "--lr-scheduler",
                "inverse_sqrt",
                "--weight-decay",
                "0.0001",
                "--max-update",
                "1000",
                "--warmup-updates",
                "4000",
                "--update-freq",
                "4",
                "--num-workers",
                "1",
                "--ddp-backend",
                "no_c10d",
                "--seed",
                "1"
            ]
        },
        {
            "name": "prep_mustc_data",
            "type": "python",
            "request": "launch",
            "program": "cs291k/prepare_data/prep_mustc_data.py",
            "console": "integratedTerminal",
            "args": [
                "--data-root",
                "/home/ubuntu/work/datasets/must-c/",
                "--task",
                "wave",
                "--ignore_fbank80",
                "--joint_spm",
                "wmt14-en-de-spm",
                "--languages",
                "de",
                "--vocab-type",
                "unigram",
                "--vocab-size",
                "10000"
            ]
        }
    ]
}