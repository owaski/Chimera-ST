{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from argparse import Namespace\n",
    "\n",
    "import torch as th\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from fairseq.data import Dictionary\n",
    "from fairseq.models.mST.w2v2_phone_transformer import W2V2Transformer\n",
    "from fairseq.data.audio.multilingual_triplet_v2_phone_dataset import (\n",
    "    MultilingualTripletDataConfig,\n",
    "    MultilingualTripletDataset,\n",
    "    MultilingualTripletDatasetCreator\n",
    ")\n",
    "from fairseq.data.audio.speech_to_text_dataset import get_features_or_waveform\n",
    "from examples.speech_to_text.data_utils import load_df_from_tsv\n",
    "from fairseq.checkpoint_utils import load_checkpoint_to_cpu\n",
    "from fairseq.data.encoders.sentencepiece_bpe import SentencepieceBPE, SentencepieceConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Namespace()\n",
    "task = Namespace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dict(vocab_filename):\n",
    "    _dict_path = vocab_filename\n",
    "    if not os.path.isfile(_dict_path):\n",
    "        raise FileNotFoundError(f\"Dict not found: {_dict_path}\")\n",
    "    _dict = Dictionary.load(_dict_path)\n",
    "    for code in codes:\n",
    "        _dict.add_symbol(MultilingualTripletDataset.LANG_TAG_TEMPLATE.format(code))\n",
    "    _dict.add_symbol('<mask>')\n",
    "    return _dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_list_filename = '/mnt/raid5/siqi/checkpoints/pretrained/mbart50.ft.n1/ML50_langs.txt'\n",
    "vocab_filename = '/mnt/raid5/siqi/checkpoints/pretrained/mbart50.ft.n1/dict.txt'\n",
    "phone_vocab_filename = '/mnt/raid5/siqi/datasets/covost2/phone_dict.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "codes = MultilingualTripletDataset.get_lang_codes(lang_list_filename)\n",
    "dict = load_dict(vocab_filename)\n",
    "with open(phone_vocab_filename, 'r') as r:\n",
    "    phone_list = [l.strip() for l in r.readlines() if l.strip() != '']\n",
    "    phone_dict = {l: idx + 1 for idx, l in enumerate(phone_list)} # leave 0 as blank\n",
    "    phone_list = ['|'] + phone_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "task.src_dict = task.tgt_dict = dict\n",
    "task.phone_dict = phone_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.w2v2_model_path = '/mnt/raid5/siqi/checkpoints/pretrained/xlsr2_300m.pt'\n",
    "args.mbart50_dir = '/mnt/raid5/siqi/checkpoints/pretrained/mbart50.ft.n1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = W2V2Transformer.build_model(args, task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_path = '/mnt/raid5/siqi/checkpoints/xlsr_phone_mbart_de_zh_ctc_phone_text/checkpoint_best.pt'\n",
    "ckpt = load_checkpoint_to_cpu(ckpt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(ckpt[\"model\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(lang_list_filename, 'r') as r:\n",
    "    lang_codes = [line.strip() for line in r.readlines() if line.strip() != \"\"]\n",
    "lang2langcode = {code[:2] : code for code in lang_codes}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "spm_config = SentencepieceConfig(sentencepiece_model='/mnt/raid0/siqi/checkpoints/pretrained/mbart50.ft.n1/sentence.bpe.model')\n",
    "spm = SentencepieceBPE(spm_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = '/mnt/raid5/siqi/datasets/covost2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_df_from_tsv('/mnt/raid5/siqi/datasets/covost2/zh-CN/train_st_zh-CN_en_phone.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                                common_voice_zh-CN_18536372\n",
       "audio                         common_voice_zh-CN_18536372.wav\n",
       "n_frames                                                88704\n",
       "src_text                                对于更高阶的导数，我们可以继续同样的过程。\n",
       "tgt_text    For derivatives of higher order, we can use th...\n",
       "speaker     c69453a9ae8cdd8ce47e767209e28e254719861de178ac...\n",
       "src_lang                                                zh-CN\n",
       "tgt_lang                                                   en\n",
       "phones      t uə ɤɐ̞ ɪ ɥ uə k ɤɐ̞ ŋ k æ o tɕ ɪ ɤɐ̞ t ɪ p æ...\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = 0\n",
    "df.iloc[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = get_features_or_waveform(\n",
    "    os.path.join(data_root, 'zh-CN', '16kHz', df.iloc[idx]['audio']),\n",
    "    need_waveform=True,\n",
    "    sample_rate=16000,\n",
    ")\n",
    "source = th.from_numpy(source).float()\n",
    "\n",
    "lang_tag = \"<lang:{}>\".format(lang2langcode['zh'])\n",
    "src_lang_tag_idx = dict.index(lang_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_tokens = source.unsqueeze(0)\n",
    "src_lengths = th.LongTensor([source.size(0)])\n",
    "src_lang_tag_indices = th.LongTensor([src_lang_tag_idx]).unsqueeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_out = model.forward_encoder(src_tokens, src_lengths, src_lang_tag_indices=src_lang_tag_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| t uə ɤɐ̞ ɪ | ɥ uə | k | ɤɐ̞ | ŋ | k | æ o | tɕ ɪ ɤɐ̞ | t ɪ | t | æ | o | ʂ | uə | o | m | ɤɐ̞ | n | kʰ | ɤɐ̞ | i | tɕ | ɪ | ɕ | y | tʰ | o | ŋ | j | æ | ŋ | t ɪ | k | uə o | tʂʰ | ɤɐ̞ |\n",
      "t uə ɤɐ̞ ɪ ɥ uə k ɤɐ̞ ŋ k æ o tɕ ɪ ɤɐ̞ t ɪ p æ o ʂ uə w uə o m ɤɐ̞ n kʰ ɤɐ̞ i tɕ ɪ ɕ y tʂʰ o ŋ l j æ ŋ t ɪ k uə o tʂʰ ɤɐ̞ ŋ\n",
      "对于更高阶的导数，我们可以继续同样的过程。\n"
     ]
    }
   ],
   "source": [
    "print(*[phone_list[tok] for tok in encoder_out.phone_logp.argmax(dim=-1).squeeze().unique_consecutive()])\n",
    "print(df.iloc[idx]['phones'])\n",
    "print(df.iloc[idx]['src_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<lang:zh_CN> ▁ 对 <mask> 于 <mask> 高 <mask> 的 <mask> 可以 <mask> 集 <mask> 的过程 <mask> 。 </s>\n",
      "▁对于 更高 阶 的 导 数 , 我们可以 继续 同样 的过程 。\n",
      "对于更高阶的导数，我们可以继续同样的过程。\n"
     ]
    }
   ],
   "source": [
    "print(*[dict[tok] for tok in encoder_out.text_logp.argmax(dim=-1).squeeze().unique_consecutive()])\n",
    "print(spm.encode(df.iloc[idx]['src_text']))\n",
    "print(df.iloc[idx]['src_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a68cd4a7ef308fe1097ac63f4e85e531ee114d7b566f56457f8a7bdc63a1a0bb"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('st')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
